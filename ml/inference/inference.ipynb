{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHgdgC843Ujf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\yosua\\Downloads\\klasifikasi-jerawat\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ],
      "source": [
        "model_dir = \"tflite/deteksi/best_float32.tflite\"\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=model_dir)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "def enlarge_bbox(x1, y1, x2, y2, scale=1.2, img_width=640, img_height=640):\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    cx = x1 + w / 2\n",
        "    cy = y1 + h / 2\n",
        "\n",
        "    new_w = w * scale\n",
        "    new_h = h * scale\n",
        "\n",
        "    new_x1 = max(0, int(cx - new_w / 2))\n",
        "    new_y1 = max(0, int(cy - new_h / 2))\n",
        "    new_x2 = min(img_width, int(cx + new_w / 2))\n",
        "    new_y2 = min(img_height, int(cy + new_h / 2))\n",
        "\n",
        "    return new_x1, new_y1, new_x2, new_y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1TDXSqK3kh-"
      },
      "outputs": [],
      "source": [
        "img_path = \"acne_list.jpg\"\n",
        "img = cv2.imread(img_path)\n",
        "img_height, img_width = img.shape[:2]\n",
        "\n",
        "input_shape = input_details[0]['shape'][1:3]\n",
        "input_tensor = cv2.resize(img, tuple(input_shape))\n",
        "input_tensor = input_tensor.astype(np.float32) / 255.0\n",
        "input_tensor = np.expand_dims(input_tensor, axis=0)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "interpreter.invoke()\n",
        "\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "detections = output_data[0] \n",
        "\n",
        "folder_dir = \"hasil_crop\"\n",
        "os.makedirs(folder_dir, exist_ok=True)\n",
        "\n",
        "for i, det in enumerate(detections):\n",
        "    x1, y1, x2, y2, conf, cls = det[:6]\n",
        "    if conf < 0.65:\n",
        "        continue\n",
        "\n",
        "    scale_x = img_width / input_shape[1]\n",
        "    scale_y = img_height / input_shape[0]\n",
        "\n",
        "    x1 = int(x1 * scale_x)\n",
        "    y1 = int(y1 * scale_y)\n",
        "    x2 = int(x2 * scale_x)\n",
        "    y2 = int(y2 * scale_y)\n",
        "\n",
        "    x1, y1, x2, y2 = enlarge_bbox(x1, y1, x2, y2, scale=1.75, img_width=img_width, img_height=img_height)\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    crop = img[y1:y2, x1:x2]\n",
        "    scale_factor = 4.5\n",
        "    resized_crop = cv2.resize(crop, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
        "    crop_path = f\"{folder_dir}/crop_{i}.jpg\"\n",
        "    cv2.imwrite(crop_path, resized_crop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d5TF74cp3rV_"
      },
      "outputs": [],
      "source": [
        "model_path = \"tflite/klasifikasi/model.tflite\"\n",
        "interpreter_clf = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter_clf.allocate_tensors()\n",
        "\n",
        "input_details_clf = interpreter_clf.get_input_details()\n",
        "output_details_clf = interpreter_clf.get_output_details()\n",
        "\n",
        "with open(\"tflite/klasifikasi/labels.json\", \"r\") as f:\n",
        "    class_indices = json.load(f)\n",
        "\n",
        "class_names = {v: k for k, v in class_indices.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWyi0UM93tKn"
      },
      "outputs": [],
      "source": [
        "def predict_image(folder_path):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            img = load_img(img_path, target_size=(224, 224))\n",
        "            img_array = img_to_array(img).astype(np.float32)\n",
        "            img_array = img_array / 255.0\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            interpreter_clf.set_tensor(input_details_clf[0]['index'], img_array)\n",
        "            interpreter_clf.invoke()\n",
        "            output_data = interpreter_clf.get_tensor(output_details_clf[0]['index'])\n",
        "\n",
        "            pred_index = np.argmax(output_data)\n",
        "            confidence = float(output_data[0][pred_index]) * 100.0\n",
        "            class_label = class_names[pred_index]\n",
        "\n",
        "            plt.figure()\n",
        "            plt.imshow(load_img(img_path))\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"{filename} : {class_label} ({confidence:.2f}%)\")\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a-hVtQAM377k"
      },
      "outputs": [],
      "source": [
        "predict_image(\"hasil_crop\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (venv)",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
